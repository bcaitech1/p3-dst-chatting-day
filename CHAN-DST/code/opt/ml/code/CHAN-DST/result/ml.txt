Namespace(attn_head=4, bert_dir='bert-base-uncased', bert_model='bert-base-uncased', combine=None, curr='attn', data_dir='/opt/ml/input/train_dataset', dev_batch_size=1, distance_metric='cosine', do_eval=False, do_eval_best_acc=False, do_lower_case=True, do_not_use_tensorboard=0, do_train=True, eval_batch_size=16, fix_utterance_encoder=None, fp16=False, gradient_accumulation_steps=1, hidden_dim=100, lamb=0.5, learning_rate=5e-05, local_rank=-1, loss_scale=0, max_label_length=32, max_seq_length=64, max_turn_length=22, model='BeliefTracker', mt_drop=0.0, no_cuda=False, num_rnn_layers=1, num_train_epochs=300, output_dir='opt/ml/code/CHAN-DST/result', patience=10.0, seed=42, target_slot='all', task_name='bert-gru-sumbt', tf_dir='tensorboard', train_batch_size=4, warmup_proportion=0.1, window=1, zero_init_rnn=False)
device: cuda n_gpu: 1, distributed training: False, 16-bits training: False
Namespace(attn_head=4, bert_dir='bert-base-uncased', bert_model='bert-base-uncased', combine=None, curr='attn', data_dir='/opt/ml/input/train_dataset', dev_batch_size=1, distance_metric='cosine', do_eval=False, do_eval_best_acc=False, do_lower_case=True, do_not_use_tensorboard=0, do_train=True, eval_batch_size=16, fix_utterance_encoder=None, fp16=False, gradient_accumulation_steps=1, hidden_dim=100, lamb=0.5, learning_rate=5e-05, local_rank=-1, loss_scale=0, max_label_length=32, max_seq_length=64, max_turn_length=22, model='BeliefTracker', mt_drop=0.0, no_cuda=False, num_rnn_layers=1, num_train_epochs=300, output_dir='opt/ml/code/CHAN-DST/result', patience=10.0, seed=42, target_slot='all', task_name='bert-gru-sumbt', tf_dir='tensorboard', train_batch_size=4, warmup_proportion=0.1, window=1, zero_init_rnn=False)
device: cuda n_gpu: 1, distributed training: False, 16-bits training: False
***** Running training *****
  Num examples = 46170
  Batch size = 4
  Num steps = 472575
max_turn_length = 14
Namespace(attn_head=4, bert_dir='bert-base-uncased', bert_model='bert-base-uncased', combine=None, curr='attn', data_dir='/opt/ml/input/train_dataset', dev_batch_size=1, distance_metric='cosine', do_eval=False, do_eval_best_acc=False, do_lower_case=True, do_not_use_tensorboard=0, do_train=True, eval_batch_size=16, fix_utterance_encoder=None, fp16=False, gradient_accumulation_steps=1, hidden_dim=100, lamb=0.5, learning_rate=5e-05, local_rank=-1, loss_scale=0, max_label_length=32, max_seq_length=64, max_turn_length=22, model='BeliefTracker', mt_drop=0.0, no_cuda=False, num_rnn_layers=1, num_train_epochs=300, output_dir='opt/ml/code/CHAN-DST/result', patience=10.0, seed=42, target_slot='all', task_name='bert-gru-sumbt', tf_dir='tensorboard', train_batch_size=4, warmup_proportion=0.1, window=1, zero_init_rnn=False)
device: cuda n_gpu: 1, distributed training: False, 16-bits training: False
***** Running training *****
  Num examples = 46170
  Batch size = 4
  Num steps = 472575
max_turn_length = 14
***** Running validation *****
  Num examples = 5075
  Batch size = 1
Loaded data!
Namespace(attn_head=4, bert_dir='bert-base-uncased', bert_model='bert-base-uncased', combine=None, curr='attn', data_dir='/opt/ml/input/train_dataset', dev_batch_size=1, distance_metric='cosine', do_eval=False, do_eval_best_acc=False, do_lower_case=True, do_not_use_tensorboard=0, do_train=True, eval_batch_size=16, fix_utterance_encoder=None, fp16=False, gradient_accumulation_steps=1, hidden_dim=100, lamb=0.5, learning_rate=5e-05, local_rank=-1, loss_scale=0, max_label_length=32, max_seq_length=64, max_turn_length=22, model='BeliefTracker', mt_drop=0.0, no_cuda=False, num_rnn_layers=1, num_train_epochs=300, output_dir='opt/ml/code/CHAN-DST/result', patience=10.0, seed=42, target_slot='all', task_name='bert-gru-sumbt', tf_dir='tensorboard', train_batch_size=4, warmup_proportion=0.1, window=1, zero_init_rnn=False)
device: cuda n_gpu: 1, distributed training: False, 16-bits training: False
***** Running training *****
  Num examples = 46170
  Batch size = 4
  Num steps = 472575
max_turn_length = 14
Namespace(attn_head=4, bert_dir='bert-base-uncased', bert_model='bert-base-uncased', combine=None, curr='attn', data_dir='/opt/ml/input/train_dataset', dev_batch_size=1, distance_metric='cosine', do_eval=False, do_eval_best_acc=False, do_lower_case=True, do_not_use_tensorboard=0, do_train=True, eval_batch_size=16, fix_utterance_encoder=None, fp16=False, gradient_accumulation_steps=1, hidden_dim=100, lamb=0.5, learning_rate=5e-05, local_rank=-1, loss_scale=0, max_label_length=45, max_seq_length=64, max_turn_length=22, model='BeliefTracker', mt_drop=0.0, no_cuda=False, num_rnn_layers=1, num_train_epochs=300, output_dir='opt/ml/code/CHAN-DST/result', patience=10.0, seed=42, target_slot='all', task_name='bert-gru-sumbt', tf_dir='tensorboard', train_batch_size=4, warmup_proportion=0.1, window=1, zero_init_rnn=False)
device: cuda n_gpu: 1, distributed training: False, 16-bits training: False
***** Running training *****
  Num examples = 46170
  Batch size = 4
  Num steps = 472575
max_turn_length = 14
***** Running validation *****
  Num examples = 5075
  Batch size = 1
Loaded data!
Namespace(attn_head=4, bert_dir='bert-base-uncased', bert_model='bert-base-uncased', combine=None, curr='attn', data_dir='/opt/ml/input/train_dataset', dev_batch_size=1, distance_metric='cosine', do_eval=False, do_eval_best_acc=False, do_lower_case=True, do_not_use_tensorboard=0, do_train=True, eval_batch_size=16, fix_utterance_encoder=None, fp16=False, gradient_accumulation_steps=1, hidden_dim=100, lamb=0.5, learning_rate=5e-05, local_rank=-1, loss_scale=0, max_label_length=60, max_seq_length=64, max_turn_length=22, model='BeliefTracker', mt_drop=0.0, no_cuda=False, num_rnn_layers=1, num_train_epochs=300, output_dir='opt/ml/code/CHAN-DST/result', patience=10.0, seed=42, target_slot='all', task_name='bert-gru-sumbt', tf_dir='tensorboard', train_batch_size=4, warmup_proportion=0.1, window=1, zero_init_rnn=False)
device: cuda n_gpu: 1, distributed training: False, 16-bits training: False
***** Running training *****
  Num examples = 46170
  Batch size = 4
  Num steps = 472575
max_turn_length = 14
***** Running validation *****
  Num examples = 5075
  Batch size = 1
Loaded data!
BertAdam (
Parameter Group 0
    b1: 0.9
    b2: 0.999
    e: 1e-06
    lr: 5e-05
    max_grad_norm: 1.0
    schedule: <pytorch_pretrained_bert.optimization.WarmupLinearSchedule object at 0x7f0b9cfee250>
    weight_decay: 0.01

Parameter Group 1
    b1: 0.9
    b2: 0.999
    e: 1e-06
    lr: 5e-05
    max_grad_norm: 1.0
    schedule: <pytorch_pretrained_bert.optimization.WarmupLinearSchedule object at 0x7f0b9cfee250>
    weight_decay: 0.0
)
Training...
